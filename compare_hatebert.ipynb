{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1e3646c-fe09-45ad-96a3-28b12be8abb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['text', 'annotator_1', 'annotator_2', 'annotator_3', 'label'],\n",
      "    num_rows: 1023\n",
      "})\n",
      "label\n",
      "0    687\n",
      "1    336\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"grammarly/detexd-benchmark\", split='test')\n",
    "print(dataset)\n",
    "print(dataset.to_pandas().label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444670f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Download hatebert models\n",
    "# https://arxiv.org/pdf/2010.12472.pdf\n",
    "# https://osf.io/tbd58/\n",
    "!wget https://files.de-1.osf.io/v1/resources/tbd58/providers/osfstorage/?zip= -O hatebert.zip\n",
    "!mkdir hatebert\n",
    "!unzip hatebert.zip -d hatebert\n",
    "!rm hatebert.zip\n",
    "\n",
    "!unzip hatebert/HateBERT_fine_tuned_models/HateBERT_abuseval.zip -d hatebert/HateBERT_fine_tuned_models\n",
    "!unzip hatebert/HateBERT_fine_tuned_models/HateBERT_hateval.zip -d hatebert/HateBERT_fine_tuned_models\n",
    "!unzip hatebert/HateBERT_fine_tuned_models/HateBERT_offenseval.zip -d hatebert/HateBERT_fine_tuned_models\n",
    "!rm hatebert/HateBERT_fine_tuned_models/HateBERT_abuseval.zip\n",
    "!rm hatebert/HateBERT_fine_tuned_models/HateBERT_hateval.zip\n",
    "!rm hatebert/HateBERT_fine_tuned_models/HateBERT_offenseval.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fbe846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import precision_recall_curve, f1_score\n",
    "import numpy as np\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "import pandas as pd\n",
    "\n",
    "metrics = []\n",
    "for name in tqdm(['hatebert/HateBERT_fine_tuned_models/HateBERT_abuseval',\n",
    "                  'hatebert/HateBERT_fine_tuned_models/HateBERT_hateval',\n",
    "                  'hatebert/HateBERT_fine_tuned_models/HateBERT_offenseval']):\n",
    "    pipe = pipeline(\"text-classification\", model=name, device=0, batch_size=8)\n",
    "    pipe.model.config.id2label = [0, 1]\n",
    "    preds = tqdm(pipe(KeyDataset(dataset, 'text'), truncation=True, top_k=None), total=len(dataset))\n",
    "    scores = np.array([next(p['score']\n",
    "                            for p in pr if p['label'] == 1)\n",
    "                       for pr in preds])\n",
    "\n",
    "    precision, recall, thresholds = precision_recall_curve(dataset['label'], scores)\n",
    "    f_scores = 2*(precision*recall)/(precision+recall)\n",
    "    optimal_threshold_index = np.argmax(f_scores)\n",
    "    optimal_threshold = thresholds[optimal_threshold_index]\n",
    "    for tag, threshold in [('', 0.5), ('_opt', optimal_threshold)]:\n",
    "        preds = scores > threshold\n",
    "        metrics.append((name + tag,) + precision_recall_fscore_support(dataset['label'], preds, average='binary')[:-1])\n",
    "    \n",
    "metrics = pd.DataFrame(metrics, columns=['model', 'precision', 'recall', 'f1'])\n",
    "metrics.model = metrics.model.str.split('/').str[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a738076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_ca075\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_ca075_level0_col0\" class=\"col_heading level0 col0\" >model</th>\n",
       "      <th id=\"T_ca075_level0_col1\" class=\"col_heading level0 col1\" >precision</th>\n",
       "      <th id=\"T_ca075_level0_col2\" class=\"col_heading level0 col2\" >recall</th>\n",
       "      <th id=\"T_ca075_level0_col3\" class=\"col_heading level0 col3\" >f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_ca075_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_ca075_row0_col0\" class=\"data row0 col0\" >HateBERT_abuseval</td>\n",
       "      <td id=\"T_ca075_row0_col1\" class=\"data row0 col1\" >86.7%</td>\n",
       "      <td id=\"T_ca075_row0_col2\" class=\"data row0 col2\" >11.6%</td>\n",
       "      <td id=\"T_ca075_row0_col3\" class=\"data row0 col3\" >20.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca075_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_ca075_row1_col0\" class=\"data row1 col0\" >HateBERT_abuseval_opt</td>\n",
       "      <td id=\"T_ca075_row1_col1\" class=\"data row1 col1\" >57.0%</td>\n",
       "      <td id=\"T_ca075_row1_col2\" class=\"data row1 col2\" >70.2%</td>\n",
       "      <td id=\"T_ca075_row1_col3\" class=\"data row1 col3\" >62.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca075_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_ca075_row2_col0\" class=\"data row2 col0\" >HateBERT_hateval</td>\n",
       "      <td id=\"T_ca075_row2_col1\" class=\"data row2 col1\" >95.2%</td>\n",
       "      <td id=\"T_ca075_row2_col2\" class=\"data row2 col2\" >6.0%</td>\n",
       "      <td id=\"T_ca075_row2_col3\" class=\"data row2 col3\" >11.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca075_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_ca075_row3_col0\" class=\"data row3 col0\" >HateBERT_hateval_opt</td>\n",
       "      <td id=\"T_ca075_row3_col1\" class=\"data row3 col1\" >41.1%</td>\n",
       "      <td id=\"T_ca075_row3_col2\" class=\"data row3 col2\" >86.0%</td>\n",
       "      <td id=\"T_ca075_row3_col3\" class=\"data row3 col3\" >55.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca075_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_ca075_row4_col0\" class=\"data row4 col0\" >HateBERT_offenseval</td>\n",
       "      <td id=\"T_ca075_row4_col1\" class=\"data row4 col1\" >75.4%</td>\n",
       "      <td id=\"T_ca075_row4_col2\" class=\"data row4 col2\" >31.0%</td>\n",
       "      <td id=\"T_ca075_row4_col3\" class=\"data row4 col3\" >43.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_ca075_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_ca075_row5_col0\" class=\"data row5 col0\" >HateBERT_offenseval_opt</td>\n",
       "      <td id=\"T_ca075_row5_col1\" class=\"data row5 col1\" >60.1%</td>\n",
       "      <td id=\"T_ca075_row5_col2\" class=\"data row5 col2\" >72.6%</td>\n",
       "      <td id=\"T_ca075_row5_col3\" class=\"data row5 col3\" >65.8%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f0a6052d580>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.style.format('{:.1%}', subset=['precision', 'recall', 'f1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9e46544-c16a-4963-8a53-23187dca753a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "570e34a01db24d98851e86dfc70534b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2805 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'precision': '48.3%', 'recall': '96.4%', 'f-score': '64.3%'}\n"
     ]
    }
   ],
   "source": [
    "# evaluate HateBERT on HatEval (Basile et al., 2019) (reported f-score was .645Â±.001)\n",
    "# run this first: founta_basile_comparison.ipynb\n",
    "import datasets\n",
    "\n",
    "df = pd.read_csv('basile_data/preds.csv')\n",
    "pipe = pipeline(\"text-classification\", model='hatebert/HateBERT_fine_tuned_models/HateBERT_hateval', device=0, batch_size=8)\n",
    "pipe.model.config.id2label = [0, 1]\n",
    "preds = tqdm(pipe(KeyDataset(datasets.Dataset.from_pandas(df), 'text'), truncation=True), total=len(df))\n",
    "preds = [p['label'] for p in preds]\n",
    "df['hateval_pred'] = preds\n",
    "df.to_csv('basile_data/preds.csv', index=False)\n",
    "print(dict(zip(['precision', 'recall', 'f-score'],\n",
    "               [f'{x:.1%}' for x in precision_recall_fscore_support(df.real, preds, average='binary')[:-1]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6cd7bf5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Note, there's a mismatch with the paper: 64.3% != .645\n",
    "# possible reasons?\n",
    "# 1) some floating-point fluctuations, different versions of torch, etc\n",
    "# 2) two positive classes are treated separately"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
