{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-api-python-client\n",
    "!pip install scikit-learn\n",
    "!pip install pandas\n",
    "!pip install datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from getpass import getpass\n",
    "import time"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the google perspective API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient import discovery\n",
    "import json\n",
    "\n",
    "API_KEY = getpass('print enter the perspective API key')\n",
    "\n",
    "client = discovery.build(\n",
    "  \"commentanalyzer\",\n",
    "  \"v1alpha1\",\n",
    "  developerKey=API_KEY,\n",
    "  discoveryServiceUrl=\"https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1\",\n",
    "  static_discovery=False,\n",
    ")\n",
    "\n",
    "def call_perspective_api(text):\n",
    "    analyze_request = {\n",
    "      'comment': { 'text': text},\n",
    "      'requestedAttributes': {\n",
    "        'TOXICITY': {}, \n",
    "        'SEVERE_TOXICITY':{},\n",
    "        'IDENTITY_ATTACK':{}, \n",
    "        'INSULT':{}, \n",
    "        'PROFANITY':{}, \n",
    "        'THREAT':{}\n",
    "        },\n",
    "      'doNotStore': True\n",
    "    }\n",
    "\n",
    "    response = client.comments().analyze(body=analyze_request).execute()\n",
    "    result = response[\"attributeScores\"]\n",
    "    return {\n",
    "      'SEVERE_TOXICITY': result['SEVERE_TOXICITY'][\"summaryScore\"]['value'],\n",
    "      'TOXICITY':result['TOXICITY'][\"summaryScore\"]['value'],\n",
    "      'IDENTITY_ATTACK':result['IDENTITY_ATTACK'][\"summaryScore\"]['value'],\n",
    "      'INSULT':result['INSULT'][\"summaryScore\"]['value'],\n",
    "      'PROFANITY':result['PROFANITY'][\"summaryScore\"]['value'],\n",
    "      'THREAT':result['THREAT'][\"summaryScore\"]['value'],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SEVERE_TOXICITY': 0.0012397766,\n",
       " 'TOXICITY': 0.017843807,\n",
       " 'IDENTITY_ATTACK': 0.0032928092,\n",
       " 'INSULT': 0.008747884,\n",
       " 'PROFANITY': 0.016479544,\n",
       " 'THREAT': 0.0076507707}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "call_perspective_api(\"This is a test sentence\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (/Users/yichen/.cache/huggingface/datasets/grammarly___csv/grammarly--detexd-benchmark-bf0a011730149f79/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"grammarly/detexd-benchmark\", split='test').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_result = []\n",
    "\n",
    "for text in dataset[\"text\"]:\n",
    "    time.sleep(3)\n",
    "    API_result.append(call_perspective_api(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATTRIBUTES_LIST = ['SEVERE_TOXICITY', 'TOXICITY', 'IDENTITY_ATTACK', 'INSULT', 'PROFANITY', 'THREAT']\n",
    "for attribute in ATTRIBUTES_LIST:\n",
    "    column_data = {attribute : [item[attribute] for item in API_result]}\n",
    "    dataset = dataset.assign(\n",
    "        **column_data\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Flag the input if either attribute's probability is greater than 0.5\n",
    "dataset['perspective-flag'] = dataset.apply(\n",
    "    lambda row: sum([int(row[attribute] > 0.5) for attribute in ATTRIBUTES_LIST]) >= 1, \n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.746268656716418,\n",
       " 'recall': 0.2976190476190476,\n",
       " 'f1-score': 0.425531914893617,\n",
       " 'support': 336}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(dataset['label'], dataset['perspective-flag'], output_dict=True)['1']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the discrepency between the number reported in the paper and the number here might caused by the different date(thus different version of perspective api) performed on the dataset, overall difference is not significant"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismograph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
